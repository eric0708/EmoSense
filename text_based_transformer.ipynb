{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training for ASR Based Speech Emotion Recogntion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch \n",
    "from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and Perform ASR on Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './Train'\n",
    "valid_dir = './Valid'\n",
    "emotion2idx_filename = './emotion2idx.json'\n",
    "idx2emotion_filename = './idx2emotion.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Label Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion2idx_dict = defaultdict(list)\n",
    "idx2emotion_dict = defaultdict(list)\n",
    "\n",
    "idx = 0\n",
    "\n",
    "for _, filename in enumerate(os.listdir(train_dir)):\n",
    "    emotion = filename.split('_')[2]\n",
    "    \n",
    "    if emotion not in emotion2idx_dict:\n",
    "        emotion2idx_dict[emotion] = idx\n",
    "        idx2emotion_dict[idx] = emotion\n",
    "        idx += 1\n",
    "\n",
    "with open(emotion2idx_filename, 'w') as json_file:\n",
    "    json.dump(emotion2idx_dict, json_file)\n",
    "\n",
    "with open(idx2emotion_filename, 'w') as json_file:\n",
    "    json.dump(idx2emotion_dict, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Label Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(emotion2idx_filename, 'r') as json_file:\n",
    "    emotion2idx_dict = json.load(json_file)\n",
    "\n",
    "with open(idx2emotion_filename, 'r') as json_file:\n",
    "    idx2emotion_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ASR Model and Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Speech2TextForConditionalGeneration were not initialized from the model checkpoint at facebook/s2t-small-librispeech-asr and are newly initialized: ['model.encoder.embed_positions.weights', 'model.decoder.embed_positions.weights']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "asr_model = Speech2TextForConditionalGeneration.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n",
    "asr_processor = Speech2TextProcessor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform ASR on Train and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text(data_dir, emotion2idx_dict, sample_rate, asr_model, asr_processor):\n",
    "    filenames = os.listdir(data_dir)\n",
    "    inputs = []\n",
    "    labels = []\n",
    "\n",
    "    for filename in filenames:\n",
    "        # load the speech file\n",
    "        speech_audio, _ = librosa.load(os.path.join(data_dir, filename), sr = sample_rate)\n",
    "\n",
    "        # perform ASR\n",
    "        input_features = asr_processor(speech_audio, sampling_rate=sample_rate, return_tensors=\"pt\").input_features\n",
    "        generated_ids = asr_model.generate(input_features=input_features)\n",
    "        transcription = asr_processor.batch_decode(generated_ids)\n",
    "        \n",
    "        # append to inputs and labels\n",
    "        inputs.append(transcription)\n",
    "        labels.append(emotion2idx_dict[filename.split('_')[2]])\n",
    "        \n",
    "    return filenames, inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suyenshuo/opt/anaconda3/envs/MMML/lib/python3.8/site-packages/transformers/models/speech_to_text/feature_extraction_speech_to_text.py:107: RuntimeWarning: divide by zero encountered in divide\n",
      "  x = np.divide(x, std)\n"
     ]
    }
   ],
   "source": [
    "train_filenames, train_inputs, train_labels = speech_to_text(train_dir, emotion2idx_dict, 16_000, asr_model, asr_processor)\n",
    "valid_filenames, valid_inputs, valid_labels = speech_to_text(valid_dir, emotion2idx_dict, 16_000, asr_model, asr_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1033_ITS_SAD_XX.wav\n",
      "[\"</s> i think i've seen this before</s>\"]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "idx = 100\n",
    "\n",
    "print(train_filenames[idx])\n",
    "print(train_inputs[idx])\n",
    "print(train_labels[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Speech_Text_Dataset(Dataset):\n",
    "    def __init__(self, data_dir, emotion2idx_dict, sample_rate, asr_model, asr_processor):\n",
    "        self.data_dir = data_dir\n",
    "        self.emotion2idx_dict = emotion2idx_dict\n",
    "        self.sample_rate = sample_rate\n",
    "        self.asr_model = asr_model\n",
    "        self.asr_processor = asr_processor\n",
    "\n",
    "        self.filenames = os.listdir(data_dir)\n",
    "        self.labels = [self.emotion2idx_dict[filename.split('_')[2]] for filename in self.filenames]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.filenames[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # load the speech file\n",
    "        speech_audio, _ = librosa.load(os.path.join(self.data_dir, filename), sr = self.sample_rate)\n",
    "\n",
    "        # perform ASR\n",
    "        input_features = asr_processor(speech_audio, sampling_rate=self.sample_rate, return_tensors=\"pt\").input_features\n",
    "        generated_ids = asr_model.generate(input_features=input_features)\n",
    "        transcription = asr_processor.batch_decode(generated_ids)\n",
    "        \n",
    "        return speech_audio , label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MMML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
